name: Production

on:
  push:
    branches: [main]

env:
  AWS_REGION: ap-southeast-2

jobs:
  lint-format:
    name: Linting and Formatting Checks
    uses: ./.github/workflows/lint-and-format.yml

  build:
    needs: lint-format
    name: Build
    runs-on: ubuntu-24.04-arm
    environment: Production
    permissions:
      id-token: write
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: ${{ secrets.AWS_ROLE_SESSION_NAME }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Echo environment variables to .env
        run: |
          echo "FRONTEND_URL=${{ secrets.FRONTEND_URL }}" >> .env
          echo "S3_BUCKET=${{ env.S3_BUCKET }}" >> .env
          echo "S3_ACCESS_KEY_ID=${{ secrets.S3_ACCESS_KEY_ID }}" >> .env
          echo "S3_SECRET_ACCESS_KEY=${{ secrets.S3_SECRET_ACCESS_KEY }}" >> .env
          echo "S3_REGION=${{ env.S3_REGION }}" >> .env

      - name: Build Docker container
        env:
          PRODUCTION_BUILD: 'true'
          FRONTEND_URL: ${{ secrets.FRONTEND_URL }}
        run: |
          docker buildx build \
          --secret id=FRONTEND_URL \
          --secret id=S3_BUCKET \
          --secret id=S3_ACCESS_KEY_ID \
          --secret id=S3_SECRET_ACCESS_KEY \
          --secret id=S3_REGION \
          --cache-from=type=local,src=/tmp/.buildx-cache \
          --cache-to=type=local,dest=/tmp/.buildx-cache-new,mode=max \
          --output type=docker,dest=cms.tar \
          --platform=linux/arm64 --file=Dockerfile -t cms .
          gzip cms.tar

      - name: Save Docker cache
        if: success()
        run: |
          rsync -a --delete /tmp/.buildx-cache-new/ /tmp/.buildx-cache/

      - name: Copy image and compose file to S3
        run: |
          aws s3 cp ./cms.tar.gz s3://${{ secrets.AWS_S3_BUCKET }}/cms/
          aws s3 cp ./docker-compose.yml s3://${{ secrets.AWS_S3_BUCKET }}/cms/

  deploy:
    needs: build
    name: Deploy
    runs-on: ubuntu-latest
    environment: Production
    steps:
      - name: Deploy on EC2
        env:
          KEY: ${{ secrets.SSH_EC2_KEY }}
          HOSTNAME: ${{ secrets.SSH_EC2_HOSTNAME }}
          USER: ${{ secrets.SSH_EC2_USER }}
        run: |
          echo "$KEY" > private_key && chmod 600 private_key
          ssh -v -o StrictHostKeyChecking=no -i private_key ${USER}@${HOSTNAME} '
              cd ~/cms
              aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/cms/cms.tar.gz .
              aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/cms/docker-compose.yml .
              docker load -i cms.tar.gz
              docker compose up -d
          '
